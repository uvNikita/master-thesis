\chapter{Related work}
\label{chap:related-work}

\section{Image classification}
\subsection{Hand-crafted features}
\subsection{Deep learning}

\section{Multi-label image classification}

\section{Transfer learning}
Usually utilization of deep learning approach introduce significant requirements: to have enough processing power and big enough image dataset. One of the most common method to reduce these constraints called transfer learning. The main principal behind it is to reuse ``knowledge'' of pretrained neural network on one task and transfer this knowledge to another one \cite{Pan2010TransferLearningSurvey, Oquab2014TransferringMidLevel}. This idea appeared when people noticed that first layers of most CNN learn to trigger on the same features: corners, edges, color conjunctions etc, therefore there is no need to discover them in each network \cite{Zeiler2014VisualizingNets}.

There are two types of transfer learning \cite{Yosinski2014HowTransferable}:
\begin{itemize}
    \item With frozen layers, when layers copied from the pretrained network do not change their weights during the backpropagation phase, in other words their learning rates are set to zero,
    \item Fine-tuning, when copied layers only start with pretrained weights, but during the training phase adjust just their values like all other layers.
\end{itemize}

Oquab et al. describe in-detail the usage of transfer learning for multi-label classification. In particular, they show how pretrained network on one category set can be used to find labels for more general categories (for example source categories might include dog type while target set may contain only general label ``dog'') or even completely new ones. \cite{Oquab2014TransferringMidLevel} Guidelines from this research will be used in the project since target NTB dataset has different set of categories compared to the ones used in the standard image collections.

Chosen method for this project, which is described in the next chapter, allows to use transfer learning in order to reduce dataset size and performance requirements. This gives possibility to answer defined research questions without the need in high-end graphics card and potentially can even improve resulting classification performance according to the recent studies \cite{Yosinski2014HowTransferable, Oquab2014TransferringMidLevel}.